# Quick Reference: Robust vs Parametric Statistics

## One-Page Cheat Sheet

### Distribution Summary

| Statistic              | Parametric (‚ùå)    | Non-Parametric (‚úÖ) | When to Use     |
|------------------------|--------------------|---------------------|-----------------|
| Central tendency       | Mean               | **Median**          | Always          |
| Spread                 | Std deviation      | **IQR** or **MAD**  | Always          |
| Variability ratio      | CV (std/mean)      | **MAD/median**      | Comparing spread|
| Percentiles            | Assuming normal    | **Direct quantile** | Always          |

### Visualization

| Plot Type              | Parametric (‚ùå)         | Non-Parametric (‚úÖ)  | Purpose           |
|------------------------|-------------------------|---------------------|-------------------|
| Distribution shape     | Histogram (bins!)       | **ECDF**            | See full data     |
| Distribution density   | KDE (smoothing!)        | **Boxplot**         | Show quartiles    |
| Comparison             | Bar with error bars     | **Quantile plot**   | Compare p50-p99   |
| Overlay                | Normal fit curve        | **(none)**          | Don't assume      |

### Outliers

| Approach               | Parametric (‚ùå)              | Non-Parametric (‚úÖ)           |
|------------------------|------------------------------|------------------------------|
| Detection              | Z-score > 3                  | **Tukey fences (IQR)**       |
| Action                 | Remove                       | **Retain & report**          |
| Interpretation         | Noise to clean               | **Tail behavior = the point**|

### Comparison (A/B Testing)

| Method                 | Parametric (‚ùå)              | Non-Parametric (‚úÖ)           |
|------------------------|------------------------------|------------------------------|
| Test statistic         | T-test (means)               | **Quantile differences**     |
| Effect size            | Cohen's d                    | **Hodges-Lehmann**           |
| Uncertainty            | Parametric CI (t-dist)       | **Bootstrap CI**             |
| Report                 | "p < 0.05"                   | **"p99: Œî=-5ms [CI:-8,-2]"** |

### Confidence Intervals

| Parameter              | Parametric (‚ùå)              | Non-Parametric (‚úÖ)           |
|------------------------|------------------------------|------------------------------|
| Mean                   | CI = mean ¬± t¬∑SE             | **Bootstrap CI on median**   |
| Variance               | Chi-squared based            | **Bootstrap CI on IQR**      |
| Percentiles            | Assume normal                | **Bootstrap CI on quantile** |

---

## Code Quick Reference

```python
from analyze.robust_stats import *

# Summary statistics
stats = describe_robust(data)
stats['median']      # Central tendency (not mean)
stats['iqr']         # Spread (not std)
stats['mad']         # Alternative spread
stats['p99']         # Tail latency
stats['tail_ratio']  # p99/p50 (heaviness)

# Specific quantiles
median(data)         # p50
quantile(data, 0.99) # p99
iqr(data)            # Q3 - Q1
mad(data)            # Median absolute deviation

# Outlier flagging (retain!)
lower, upper, flagged = tukey_fences(data, k=1.5)
# DO NOT REMOVE flagged values

# Bootstrap CI
p99, lower, upper = bootstrap_ci_quantile(data, q=0.99, n_bootstrap=10000)
print(f"p99: {p99:.2f} [95% CI: {lower:.2f}, {upper:.2f}]")

# Compare two groups
diff, ci_low, ci_high = quantile_difference_ci(baseline, treatment, q=0.99)
print(f"Œîp99: {diff:.2f} [95% CI: {ci_low:.2f}, {ci_high:.2f}]")

# Robust location shift
shift = hodges_lehmann_estimator(baseline, treatment)
```

---

## When to Use What

### ‚úÖ Always Use Non-Parametric For:
- Latency measurements
- Cache miss counts
- Bandwidth/throughput
- Time-to-completion
- Any heavy-tailed data
- Small sample sizes
- Unknown distributions

### ‚ùå Parametric Might Be OK For:
- Extremely large samples (n > 10,000) where CLT applies
- Data that is provably normal (rare in systems!)
- Quick approximations (but note limitations)

### ü§î When In Doubt:
**Use non-parametric.** It's always safe.

---

## Red Flags in Papers/Reports

If you see these, the analysis is probably wrong:

‚ùå "We removed outliers using z-score > 3"  
‚ùå "Mean latency ¬± standard deviation"  
‚ùå "T-test shows p < 0.05"  
‚ùå "Normal distribution overlay"  
‚ùå "We assume normal distribution"  
‚ùå "Histogram with arbitrary bins"  

‚úÖ What you should see instead:

‚úÖ "Median latency (IQR)"  
‚úÖ "p99 latency with bootstrap CI"  
‚úÖ "Quantile comparison at p50, p90, p99"  
‚úÖ "ECDF visualization"  
‚úÖ "Non-parametric methods (no distributional assumptions)"  
‚úÖ "Outliers retained as meaningful tail behavior"  

---

## Emergency Decision Tree

```
Do you have systems performance data?
‚îú‚îÄ YES ‚Üí Use non-parametric methods (this guide)
‚îî‚îÄ NO ‚Üí Maybe parametric is OK (but still safer to use non-parametric)

Is your data heavy-tailed?
‚îú‚îÄ YES ‚Üí Definitely non-parametric
‚îú‚îÄ NO ‚Üí Are you sure? Check p99/p50 ratio
‚îî‚îÄ Don't know ‚Üí Use non-parametric to be safe

Do you care about tail latency (p99)?
‚îú‚îÄ YES ‚Üí Non-parametric, report quantiles
‚îî‚îÄ NO ‚Üí You should care (it matters for user experience)

Are reviewers likely to question assumptions?
‚îú‚îÄ YES (academic paper) ‚Üí Non-parametric mandatory
‚îú‚îÄ MAYBE (tech report) ‚Üí Non-parametric recommended
‚îî‚îÄ NO (internal only) ‚Üí Still use non-parametric (it's correct!)
```

---

## Common Mistakes to Avoid

### ‚ùå Mistake 1: "My data looks normal"
**Reality:** Visual inspection is unreliable. Tails often hidden in plots.  
**Fix:** Always check tail ratio (p99/p50). If > 1.5x, use non-parametric.

### ‚ùå Mistake 2: "I'll just remove outliers"
**Reality:** Outliers = the performance problem you're measuring.  
**Fix:** Flag but retain. Report p99 explicitly.

### ‚ùå Mistake 3: "T-test is standard"
**Reality:** T-test assumes normality. Systems data violates this.  
**Fix:** Use quantile differences with bootstrap CI.

### ‚ùå Mistake 4: "Mean is easier to interpret"
**Reality:** Mean is unstable in heavy tails.  
**Fix:** Report median. It's more stable and interpretable.

### ‚ùå Mistake 5: "I have a large sample"
**Reality:** Large n doesn't fix non-normality for inference.  
**Fix:** Use non-parametric. They scale to large n just fine.

---

## Final Rule

**When analyzing systems performance data:**

> Median, IQR, quantiles, ECDF, bootstrap.  
> No means, no stds, no normal fits, no t-tests.

Period.
